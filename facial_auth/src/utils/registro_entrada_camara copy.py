# src/utils/registro_entrada_camara.py (versi√≥n con validaci√≥n de movimiento)

import cv2
from multiprocessing import Process
from tkinter import Tk, Label
from PIL import Image, ImageTk
from deepface import DeepFace
import time
from scipy.spatial.distance import cosine
from src.services.registro_entrada_service import registrar_entrada
import numpy as np

def mostrar_camara(embedding_db, id_usuario):
    print("üß† Embedding recibido desde base de datos:")
    print(f"üßë ID usuario: {id_usuario}")
    print(f"üß¨ Embedding (primeros 5 valores): {embedding_db[:5]}...")

    # Configuraci√≥n de c√°mara optimizada
    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 15)

    if not cap.isOpened():
        print("‚ùå No se pudo abrir la c√°mara")
        return

    root = Tk()
    root.title("REGISTRO ENTRADA")
    root.attributes('-topmost', True)
    root.lift()
    root.after(100, lambda: root.attributes('-topmost', False))

    lmain = Label(root)
    lmain.pack()
    
    # Variables de control
    start_time = time.time()
    last_recognition_time = 0
    recognition_interval = 2  # Segundos entre reconocimientos
    UMBRAL_SIMILITUD = 0.3
    UMBRAL_MOVIMIENTO = 5000  # Umbral para detectar movimiento brusco
    last_face_region = None
    reconocimiento_realizado = False
    estado_reconocimiento = "analizando"
    frame_anterior = None
    
    def update_frame():
        nonlocal last_recognition_time, frame_anterior
        
        if reconocimiento_realizado:
            return
            
        ret, frame = cap.read()
        if not ret:
            lmain.after(30, update_frame)
            return
            
        # Detecci√≥n de movimiento brusco
        movimiento_detectado = False
        if frame_anterior is not None:
            diferencia = cv2.absdiff(frame, frame_anterior)
            gris = cv2.cvtColor(diferencia, cv2.COLOR_BGR2GRAY)
            _, umbral = cv2.threshold(gris, 25, 255, cv2.THRESH_BINARY)
            movimiento = cv2.countNonZero(umbral)
            if movimiento > UMBRAL_MOVIMIENTO:
                print(f"‚ö†Ô∏è Movimiento brusco detectado: {movimiento}")
                movimiento_detectado = True
        
        frame_anterior = frame.copy()
        
        # Mostrar imagen en Tkinter
        display_frame = frame.copy()
        
        # Dibujar cuadro seg√∫n estado
        if last_face_region and not movimiento_detectado:
            x, y, w, h = last_face_region
            if estado_reconocimiento == "reconocido":
                color = (0, 255, 0)  # Verde
                texto = "RECONOCIDO"
            elif estado_reconocimiento == "no_reconocido":
                color = (0, 0, 255)  # Rojo
                texto = "NO RECONOCIDO"
            else:  # analizando
                color = (0, 255, 255)  # Amarillo
                texto = "ANALIZANDO..."
            
            cv2.rectangle(display_frame, (x, y), (x+w, y+h), color, 2)
            cv2.putText(display_frame, texto, (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        elif movimiento_detectado:
            cv2.putText(display_frame, "MOVIMIENTO DETECTADO", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        cv2image = cv2.resize(display_frame, (640, 480))
        cv2image = cv2.cvtColor(cv2image, cv2.COLOR_BGR2RGB)
        img = Image.fromarray(cv2image)
        imgtk = ImageTk.PhotoImage(image=img)
        lmain.imgtk = imgtk
        lmain.configure(image=imgtk)

        # Control de tiempo para reconocimiento
        current_time = time.time()
        if (not reconocimiento_realizado and 
            not movimiento_detectado and
            current_time - start_time > 3 and 
            current_time - last_recognition_time > recognition_interval):
            
            last_recognition_time = current_time
            try:
                root.after(0, lambda: process_recognition(frame))
            except Exception as e:
                print("‚ùå Error en reconocimiento:", str(e))

        lmain.after(30, update_frame)
    
    def process_recognition(frame):
        nonlocal last_face_region, reconocimiento_realizado, estado_reconocimiento
        
        if reconocimiento_realizado:
            return
            
        try:
            estado_reconocimiento = "analizando"
            
            # Validaci√≥n adicional: requiere rostro centrado
            height, width = frame.shape[:2]
            result = DeepFace.represent(
                img_path=frame,
                model_name='Facenet',
                enforce_detection=True,
                detector_backend='opencv'
            )

            if result and len(result) > 0 and "embedding" in result[0]:
                if "facial_area" in result[0]:
                    face = result[0]["facial_area"]
                    last_face_region = (face["x"], face["y"], face["w"], face["h"])
                    
                    # Validar posici√≥n del rostro (debe estar relativamente centrado)
                    x_center = face["x"] + face["w"]/2
                    y_center = face["y"] + face["h"]/2
                    
                    margen = 0.3  # 30% de margen en los bordes
                    if (x_center < width * margen or 
                        x_center > width * (1-margen) or
                        y_center < height * margen or 
                        y_center > height * (1-margen)):
                        print("‚ö†Ô∏è Rostro muy cerca del borde, ignorando...")
                        estado_reconocimiento = "no_reconocido"
                        return
                
                embedding_live = result[0]["embedding"]
                distancia = cosine(embedding_live, embedding_db)
                print(f"üîç Distancia coseno: {distancia:.4f}")

                # Validaci√≥n estricta para evitar falsos positivos
                if distancia < UMBRAL_SIMILITUD:
                    # Requerir m√∫ltiples coincidencias consecutivas
                    if not hasattr(process_recognition, 'coincidencias_consecutivas'):
                        process_recognition.coincidencias_consecutivas = 0
                    
                    process_recognition.coincidencias_consecutivas += 1
                    print(f"‚úÖ Coincidencia {process_recognition.coincidencias_consecutivas}/3")
                    
                    if process_recognition.coincidencias_consecutivas >= 3:
                        print(f"‚úÖ‚úÖ‚úÖ Coincidencia confirmada para usuario ID {id_usuario}")
                        reconocimiento_realizado = True
                        estado_reconocimiento = "reconocido"
                        
                        registrar_entrada(id_usuario)
                        print("üìù Registro de entrada realizado. Cerrando c√°mara...")
                        root.after(2000, root.destroy)
                else:
                    process_recognition.coincidencias_consecutivas = 0
                    estado_reconocimiento = "no_reconocido"
        except Exception as e:
            print("‚ùå Error al comparar embedding:", str(e))
            estado_reconocimiento = "no_reconocido"
            last_face_region = None
    
    update_frame()
    root.mainloop()
    cap.release()
    cv2.destroyAllWindows()

def iniciar_camara_tkinter(embedding_db, id_usuario):
    Process(target=mostrar_camara, args=(embedding_db, id_usuario)).start()